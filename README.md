<p align="center">
  <img src="./img.png" alt="Project Banner" width="100%">
</p>

AI Based Attendance Manegment System üéØ

## Basic Details

### Team Name:Intellecta

### Team Members
- Member 1: Punnya Sudarsan - Ahalia school of engineering and technology
- Member 2:Vismaya B - Ahalia school of engineering and technology

### Hosted Project Link
[mention your project hosted link here]

### Project Description
The AI-Based Attendance Management System uses facial recognition technology to automatically record student attendance. The system captures images through a camera, detects and recognizes faces using AI algorithms, and matches them with a stored database to mark attendance accurately.

It reduces manual effort, prevents proxy attendance, and stores records digitally for easy monitoring and analysis. This smart solution improves efficiency, accuracy, and transparency in educational institutions.

### The Problem statement
Proxy and time consuming attendance system 

### The Solution
Ai Based Attendance Management System

---

## Technical Details

### Technologies/Components Used

**For Software:**
- Languages used: [html,css,javascript,python,teachable machines]
- Frameworks used: [flask,machine learning]
- Libraries used: [absl-py==2.4.0
astunparse==1.6.3
beautifulsoup4==4.14.3
blinker==1.9.0
certifi==2026.2.25
cffi==2.0.0
charset-normalizer==3.4.4
click==8.3.1
colorama==0.4.6
cryptography==46.0.5
deepface==0.0.79
face-recognition-models==0.3.0
filelock==3.24.3
fire==0.7.1
Flask==3.1.3
flask-cors==6.0.2
Flask-SQLAlchemy==3.1.1
flatbuffers==25.12.19
gast==0.7.0
gdown==5.2.1
google-auth==2.48.0
google-auth-oauthlib==1.3.0
google-pasta==0.2.0
greenlet==3.3.2
grpcio==1.78.0
gunicorn==25.1.0
h5py==3.15.1
idna==3.11
itsdangerous==2.2.0
Jinja2==3.1.6
joblib==1.5.3
keras==2.15.0
libclang==18.1.1
lightdsa==0.0.3
lightecc==0.0.4
lightphe==0.0.20
lz4==4.4.5
Markdown==3.10.2
markdown-it-py==4.0.0
MarkupSafe==3.0.3
mdurl==0.1.2
ml-dtypes==0.2.0
mpmath==1.3.0
mtcnn==1.0.0
namex==0.1.0
numpy==1.26.4
oauthlib==3.3.1
opencv-python==4.8.1.78
opt_einsum==3.4.0
optree==0.19.0
packaging==26.0
pandas==2.3.3
pillow==12.1.1
protobuf==4.25.8
pyasn1==0.6.2
pyasn1_modules==0.4.2
pycparser==3.0
Pygments==2.19.2
PySocks==1.7.1
python-dateutil==2.9.0.post0
python-dotenv==1.2.1
pytz==2025.2
requests==2.32.5
requests-oauthlib==2.0.0
retina-face==0.0.17
rich==14.3.3
rsa==4.9.1
six==1.17.0
soupsieve==2.8.3
SQLAlchemy==2.0.47
sympy==1.14.0
tensorboard==2.15.2
tensorboard-data-server==0.7.2
tensorflow==2.15.0
tensorflow-estimator==2.15.0
tensorflow-intel==2.15.0
tensorflow-io-gcs-filesystem==0.31.0
termcolor==3.3.0
tqdm==4.67.3
typing_extensions==4.15.0
tzdata==2025.3
urllib3==2.6.3
Werkzeug==3.1.6
wrapt==1.14.2
]
- Tools used: [VS Code]

**For Hardware:**
- Main components: [List main components]
- Specifications: [Technical specifications]
- Tools required: [List tools needed]

---

## Features

List the key features of your project:
- Feature 1: [Face Detection & Recognition ‚Äì Automatically detects and identifies students using AI-based facial recognition.]
- Feature 2: [Real-Time Attendance Marking ‚Äì Captures faces through a camera and marks attendance instantly.]
- Feature 3: [Automated Hourly Verification ‚Äì Re-checks student presence at scheduled intervals]
- Feature 4: [Prevents Proxy Attendance ‚Äì Eliminates fake or manual attendance marking.]

---

## Implementation

### For Software:

#### Installation
```bash
[Installation commands - e.g., npm install, pip install -r requirements.txt]
```

#### Run
```bash
[Run commands - e.g., npm start, python app.py]
```

### For Hardware:

#### Components Required
[List all components needed with specifications]

#### Circuit Setup
[Explain how to set up the circuit]

---

## Project Documentation

### For Software:

#### Screenshots (Add at least 3)

![Screenshot1]<img width="1814" height="878" alt="Screenshot 2026-02-28 013622" src="https://github.com/user-attachments/assets/a136364f-ac48-4aec-9230-f33ee984b3ec" />

This is the homepage of the attendance manegement system.in this already two students facial recognition has been stored

![Screenshot2]<img width="1904" height="932" alt="Screenshot 2026-02-28 014616" src="https://github.com/user-attachments/assets/bee6cef2-793e-4444-8365-5715787c6e0b" />

here vismaya's face has been detected by the camera and marked as present and manya haven't attented the class so she is marked as absent 
![Screenshot3](Add screenshot 3 here with proper name)
*Add caption explaining what this shows*

#### Diagrams

**System Architecture:**

![Architecture Diagram](docs/architecture.png)
*Explain your system architecture - components, data flow, tech stack interaction*

**Application Workflow:**

![Workflow](docs/workflow.png)
The front page is stored with students previously stored facial recogonised data,it also includes the data of total number of students,number of students present and absent and also a webcam scanner is ready to detect the students---->Those students who attended the class is detected through the webcam ---->the detected images of the students are compared with their stored data---->if the student's data  matches with the stored data it will be marked as present or else absent 

---

### For Hardware:

#### Schematic & Circuit

![Circuit](Add your circuit diagram here)
*Add caption explaining connections*

![Schematic](Add your schematic diagram here)
*Add caption explaining the schematic*

#### Build Photos

![Team](Add photo of your team here)

![Components](Add photo of your components here)
*List out all components shown*

![Build](Add photos of build process here)
*Explain the build steps*

![Final](Add photo of final product here)
*Explain the final build*

---

## Additional Documentation

### For Web Projects with Backend:

#### API Documentation

**Base URL:** `https://api.yourproject.com`

##### Endpoints

**GET /api/endpoint**
- **Description:** [What it does]
- **Parameters:**
  - `param1` (string): [Description]
  - `param2` (integer): [Description]
- **Response:**
```json
{
  "status": "success",
  "data": {}
}
```

**POST /api/endpoint**
- **Description:** [What it does]
- **Request Body:**
```json
{
  "field1": "value1",
  "field2": "value2"
}
```
- **Response:**
```json
{
  "status": "success",
  "message": "Operation completed"
}
```

[Add more endpoints as needed...]

---

### For Mobile Apps:

#### App Flow Diagram

![App Flow](docs/app-flow.png)
*Explain the user flow through your application*

#### Installation Guide

**For Android (APK):**
1. Download the APK from [Release Link]
2. Enable "Install from Unknown Sources" in your device settings:
   - Go to Settings > Security
   - Enable "Unknown Sources"
3. Open the downloaded APK file
4. Follow the installation prompts
5. Open the app and enjoy!

**For iOS (IPA) - TestFlight:**
1. Download TestFlight from the App Store
2. Open this TestFlight link: [Your TestFlight Link]
3. Click "Install" or "Accept"
4. Wait for the app to install
5. Open the app from your home screen

**Building from Source:**
```bash
# For Android
flutter build apk
# or
./gradlew assembleDebug

# For iOS
flutter build ios
# or
xcodebuild -workspace App.xcworkspace -scheme App -configuration Debug
```

---

### For Hardware Projects:

#### Bill of Materials (BOM)

| Component | Quantity | Specifications | Price | Link/Source |
|-----------|----------|----------------|-------|-------------|
| Arduino Uno | 1 | ATmega328P, 16MHz | ‚Çπ450 | [Link] |
| LED | 5 | Red, 5mm, 20mA | ‚Çπ5 each | [Link] |
| Resistor | 5 | 220Œ©, 1/4W | ‚Çπ1 each | [Link] |
| Breadboard | 1 | 830 points | ‚Çπ100 | [Link] |
| Jumper Wires | 20 | Male-to-Male | ‚Çπ50 | [Link] |
| [Add more...] | | | | |

**Total Estimated Cost:** ‚Çπ[Amount]

#### Assembly Instructions

**Step 1: Prepare Components**
1. Gather all components listed in the BOM
2. Check component specifications
3. Prepare your workspace
![Step 1](images/assembly-step1.jpg)
*Caption: All components laid out*

**Step 2: Build the Power Supply**
1. Connect the power rails on the breadboard
2. Connect Arduino 5V to breadboard positive rail
3. Connect Arduino GND to breadboard negative rail
![Step 2](images/assembly-step2.jpg)
*Caption: Power connections completed*

**Step 3: Add Components**
1. Place LEDs on breadboard
2. Connect resistors in series with LEDs
3. Connect LED cathodes to GND
4. Connect LED anodes to Arduino digital pins (2-6)
![Step 3](images/assembly-step3.jpg)
*Caption: LED circuit assembled*

**Step 4: [Continue for all steps...]**

**Final Assembly:**
![Final Build](images/final-build.jpg)
*Caption: Completed project ready for testing*

---

### For Scripts/CLI Tools:

#### Command Reference

**Basic Usage:**
```bash
python script.py [options] [arguments]
```

**Available Commands:**
- `command1 [args]` - Description of what command1 does
- `command2 [args]` - Description of what command2 does
- `command3 [args]` - Description of what command3 does

**Options:**
- `-h, --help` - Show help message and exit
- `-v, --verbose` - Enable verbose output
- `-o, --output FILE` - Specify output file path
- `-c, --config FILE` - Specify configuration file
- `--version` - Show version information

**Examples:**

```bash
# Example 1: Basic usage
python script.py input.txt

# Example 2: With verbose output
python script.py -v input.txt

# Example 3: Specify output file
python script.py -o output.txt input.txt

# Example 4: Using configuration
python script.py -c config.json --verbose input.txt
```

#### Demo Output

**Example 1: Basic Processing**

**Input:**
```
This is a sample input file
with multiple lines of text
for demonstration purposes
```

**Command:**
```bash
python script.py sample.txt
```

**Output:**
```
Processing: sample.txt
Lines processed: 3
Characters counted: 86
Status: Success
Output saved to: output.txt
```

**Example 2: Advanced Usage**

**Input:**
```json
{
  "name": "test",
  "value": 123
}
```

**Command:**
```bash
python script.py -v --format json data.json
```

**Output:**
```
[VERBOSE] Loading configuration...
[VERBOSE] Parsing JSON input...
[VERBOSE] Processing data...
{
  "status": "success",
  "processed": true,
  "result": {
    "name": "test",
    "value": 123,
    "timestamp": "2024-02-07T10:30:00"
  }
}
[VERBOSE] Operation completed in 0.23s
```

---

## Project Demo

### Video
https://drive.google.com/file/d/1xT1QEqQS4DB2E1OuimjSz_9P4Kt3mW_W/view?usp=sharing

*Explain what the video demonstrates - key features, user flow, technical highlights*

### Additional Demos
[Add any extra demo materials/links - Live site, APK download, online demo, etc.]

---

## AI Tools Used (Optional - For Transparency Bonus)

If you used AI tools during development, document them here for transparency:

**Tool Used:** [e.g., GitHub Copilot, v0.dev, Cursor, ChatGPT, Claude]

**Purpose:** [What you used it for]
- Example: "Generated boilerplate React components"
- Example: "Debugging assistance for async functions"
- Example: "Code review and optimization suggestions"

**Key Prompts Used:**
- "Create a REST API endpoint for user authentication"
- "Debug this async function that's causing race conditions"
- "Optimize this database query for better performance"

**Percentage of AI-generated code:** [Approximately X%]

**Human Contributions:**
- Architecture design and planning
- Custom business logic implementation
- Integration and testing
- UI/UX design decisions

*Note: Proper documentation of AI usage demonstrates transparency and earns bonus points in evaluation!*

---

## Team Contributions

- [Name 1]: [Specific contributions - e.g., Frontend development, API integration, etc.]
- [Name 2]: [Specific contributions - e.g., Backend development, Database design, etc.]
- [Name 3]: [Specific contributions - e.g., UI/UX design, Testing, Documentation, etc.]

---

## License

This project is licensed under the [LICENSE_NAME] License - see the [LICENSE](LICENSE) file for details.

**Common License Options:**
- MIT License (Permissive, widely used)
- Apache 2.0 (Permissive with patent grant)
- GPL v3 (Copyleft, requires derivative works to be open source)

---

Made with ‚ù§Ô∏è at TinkerHub
